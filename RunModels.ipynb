{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import utils.run\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Global parameters\n",
    "EXPERIMENT = 'supervised_pretraining_WSJ/'\n",
    "experiment_name = 'CT_new_software_test'\n",
    "num_runs= 2 #Should either be an integer to commence all runs or list of specific runs \n",
    "           #(ie. num_runs=5 with run model 5 times, where num_runs=[5] with run only run 5)\n",
    "gpu = 1 # gpu=1 use gpu, gpu=0 use cpu\n",
    "stage = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILE VARIABLES\n",
    "PRETRAIN_MODELNAME_ADITIONS = 'new_software_test' #extra suffix for the pretraining folder\n",
    "TRAIN_MODELNAME_ADITIONS = 'new_software_test' #extra suffix for the training folder\n",
    "### General\n",
    "OVERWRITE = False #Default: False | whether any files should be overwritten\n",
    "#EXPERIMENT = 'supervised_pretraining_WSJ/' #Default: supervised_pretraining_<CORPUS> | experiment folder **************************************\n",
    "#ROOT = '/mnt/c/files/research/projects/vid_game/data/'\n",
    "ROOT = '/fs/clip-realspeech/projects/vid_game/data/' #Default: /fs/clip-realspeech/projects/vid_game/data | root folder on clip cluster\n",
    "PARAMS_FOLDER = 'params' #Default: params | folder to store intermediate parameter files\n",
    "\n",
    "### For Pretrain\n",
    "PHONES_FILE = 'pretrain_phones' #Default: pretrain_phones | file containing phone list for pretraining\n",
    "PRETRAIN_SEGMENTS_FILE = 'pretrain_segments' #Default: pretrain_segments | file containing segments list for pretraining\n",
    "PRETRAIN_ALIGNMENTS_FILE = 'pretrain_alignments' #Default: pretrain_alignments | file containing alignments list for pretraining\n",
    "WAVS_FOLDER = 'wavs_WSJ/' #Default: wavs_<CORPUS>/ | folder containing pretraining wavs  **************************************\n",
    "\n",
    "### For Validation\n",
    "VALIDATION_SEGMENTS_FILE = 'validation_segments' #Default: validation_segments | file containing segments list for pretraining validation\n",
    "VALIDATION_ALIGNMENTS_FILE = 'validation_alignments' #Default: validation_alignments | file containing alignments list for pretraining validation\n",
    "VALIDATION_COPORA = ('WSJ',) #Default: Same as pretraining corpus | name of corpus to use for validation  **************************************\n",
    "\n",
    "### For Train\n",
    "STATE_FILE = 'states_WSJ_correct' #Default: states_WDJ_correct (was states_new_realspeech) | states file to use for training\n",
    "REWARD_FILE = 'rewards' #Default: rewards | rewards file to use for training\n",
    "EPISODE_FILE = 'episodes_full' #Default: episodes_full | episodes file to use for training\n",
    "TRANSITION_FILE = 'transitions' #Default: transitions | transitions file to use for training\n",
    "ACTION_FILE = 'actions' #Default: actions | actions file to use for training\n",
    "LOCATION_FILE = 'locations' #Default: locations | locations file to use for training\n",
    "SIMPLE_STATE_FILE = 'states_WSJ_correct' #Default: states_synthesized (was states_simple) | Simple list of files to use during results processing\n",
    "GAME_WAVS_FOLDER = 'wavs_WSJ/' #Default: wavs_WSJ/ (was wavs for English) | Folder storing audio files for training\n",
    "\n",
    "MODEL_FOLDER = 'models/' #Default: models/  | name of model output folder\n",
    "OUT_FOLDER = 'exp/'  #Default: exp/ | name of experiment run folder\n",
    "LOCATION_OUT_FILE = 'location' #Default: location  | name of location output file\n",
    "ACTION_OUT_FILE = 'action' #Default: action | name of action output file\n",
    "LOSS_OUT_FILE = 'loss' #Default: loss | name of loss ouptut file\n",
    "STATE_OUT_FILE = 'state' #Default: state | name of state output file\n",
    "REWARD_OUT_FILE = 'reward' #Default: reward | name of reward output file\n",
    "RESULTS_FILE = 'results' #Default: results | name of result output file\n",
    "\n",
    "### For Test\n",
    "SIMPLE_STATE_TEST_FILE='test_states_simple' #Default: test_states_simple | NOTE CURRENTLY REQUIED Simple list of files to use during test results processing\n",
    "ABX_WAVS_FOLDER = 'wavs_WSJ/'    #Default: wavs_WSJ/ (was wavs for English) | Folder storing audio samples for ABX\n",
    "\n",
    "#########################################cd /fs/clip\n",
    "### MODEL PARAMETERS\n",
    "### General\n",
    "BATCH_SIZE = 32 #Default: 32 | Size of batch to sample during training\n",
    "UPDATES = 25 #Default: 25 | How often to print updates\n",
    "\n",
    "KERNEL = 5 #Default: 5 | Size of convolution kernel\n",
    "STRIDE = 1 #Default: 1 | Stride of convolution\n",
    "CONV1CHANNELS = 32 #Default: 32 | Number of channels in 1st convolution\n",
    "CONV2CHANNELS = 32 #Default: 32 | Number of channels in 1st convolution\n",
    "CONV3CHANNELS = 32 #Default: 32 | Number of channels in 1st convolution\n",
    "MIDSIZE = 40 #Default: 40 | Number of nodes in linear layer\n",
    "CONV_FREEZE = True #Default: False | Whether to freeze convolutional layers\n",
    "CONV_FREEZE_LAYER = 0 #Default: 0 | Which convolutional layers should be frozen during training\n",
    "FREEZE_LAYER_TIME = 0 #Default: 0 | At what episode convolutional layers should be frozen\n",
    "LAYERS = (CONV1CHANNELS, CONV2CHANNELS, CONV3CHANNELS, MIDSIZE) # Does not need edited\n",
    "SAMPLE_RATE = 16000 #Default: 16000 | Sample rate of acoustic input\n",
    "WINDOW_SIZE = 0.2 #Default: 0.2 | Window size of acoustic token\n",
    "SPEC_WINDOW_LENGTH = 400 #Default: 400 | Window length for spectrogram calculation\n",
    "SPEC_WINDOW_HOP = 160 #Default: 160 | Spectrogram window hop size\n",
    "N_FFT = 400 #Default: 400 | N_FFT parameter for spectrogram calculation\n",
    "\n",
    "### For Pretrain\n",
    "PRETRAIN_LR = 0.09 #Default\" 0.09 | Learning rate during training \n",
    "GAME_MODE = 'correct' #Default: oneshot | Training game type\n",
    "PRETRAIN_EPOCHS = 25 #Default: 25 | Number of epochs during pretraining\n",
    "\n",
    "### For Validation\n",
    "LOSS_TYPE = 'ewc' #Default: ewc | (or standard) Type of loss function to use during training\n",
    "FISCHER_CORPUS='WSJ' #Default: Same as pretraining corpus | Corpus for which to calculate fischer coefficients**************************************\n",
    "FISCHER_FILE = 'fischercoeffs' #Default: fischercoeffs | Name of fischer coefficient filer\n",
    "EWC_IMPORTANCE = 0.01 #Default: ??? | EWC Importance Weighting Coefficient\n",
    "\n",
    "### For Train\n",
    "GAMMA = 0.9 #Default: 0.9 | Future reward decay parameter Gamma\n",
    "EPS_START = 0.99 #Default: 0.99 | Starting Epsilon Value\n",
    "EPS_END = 0.05 #Default: 0.05 | Final Epsilon value\n",
    "EPS_DECAY = 300 #Default: 300 | Epsilon decay factor\n",
    "TARGET_UPDATE = 5 #Default: 5 | How often to update target network to policy network\n",
    "TRAIN_LR = 0.05 #Default: 0.05 | Learning rate during training\n",
    "MEM_SIZE = 10000 #Default: 10000 | Size of RL replay memory\n",
    "NUM_PHONES = 39   #Default: 36 (Japanese), 39 (English) | Number of phones in pretrained corpus **************************************\n",
    "CONNECTION_LAYER = 'phone' #Default: phone | Layer at which to connect video game layers to pretrained layers\n",
    "STIMULUS_REPS = 8 #Default: 8 | Number of times to repeat stimulus before moving to next trial\n",
    "MOVE_SEPERATION = 1 #Default: 1\n",
    "WAITTIME = 0 #Default: 0 | How long to wait before taking action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = experiment_name+'_'+str(time.time())[1:10]\n",
    "ROOT = ROOT + EXPERIMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parameters included in model names\n",
    "### Pretrain\n",
    "- PRETRAIN_MODELNAME\n",
    "- PRETRAIN_LR\n",
    "- KERNEL\n",
    "- STRIDE\n",
    "- BATCH_SIZE\n",
    "- PRETRAIN_EPOCHS\n",
    "- PRETRAIN_MODELNAME_ADITIONS\n",
    "\n",
    "### Train\n",
    "- TRAIN_MODELNAME\n",
    "- GAME_MODE\n",
    "- GAMMA\n",
    "- EPS_DECAY\n",
    "- TARGET_UPDATE\n",
    "- WAITTIME\n",
    "- KERNEL\n",
    "- STRIDE\n",
    "- CONV_FREEZE_LAYER\n",
    "- FREEZE_LAYER_TIME\n",
    "- LOSS_TYPE\n",
    "- EWC_IMPORTANCE\n",
    "- TRAIN_MODELNAME_ADITIONS\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Parameter Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dicts = None\n",
    "ps = {}\n",
    "for key in dir():\n",
    "    try:\n",
    "        if key not in ['argparse','json','ps','save_params', 'f', 'args', 'parser', 'exit', 'get_ipython',\n",
    "                       'parameter_dicts', 'In', 'Out', 'os', 'quit', 'shutil', 'utils', 'time'] and key[0] != '_':\n",
    "            ps[key] = globals()[key]\n",
    "    except:\n",
    "         pass\n",
    "parameter_dicts = utils.run.create_param_dictionaries(ps)\n",
    "#print(len(parameter_dicts))\n",
    "#parameter_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_runs: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/fs/clip-realspeech/projects/vid_game/software/archive/CT_new_software_test_6449935341'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save parameters here\n",
    "for ind in range(len(parameter_dicts)):\n",
    "    parameter_dicts[ind]['param_name'] ='../params/'+experiment_name + '_' + str(ind) + '.params'\n",
    "    parameter_dicts[ind]['model_id'] = str(ind)\n",
    "    \n",
    "    this_run = parameter_dicts[ind]\n",
    "    #print(type(this_run))\n",
    "    \n",
    "    parameter_dicts[ind]['PRETRAIN_MODELNAME'] = 'pretrain_lr' + str(this_run['PRETRAIN_LR'])+ '_kernel' + str(this_run['KERNEL']) + \\\n",
    "                '_stride' + str(this_run['STRIDE']) + '_batchsize' + \\\n",
    "                str(this_run['BATCH_SIZE']) + '_epochs' + \\\n",
    "                str(this_run['PRETRAIN_EPOCHS'])+ this_run['PRETRAIN_MODELNAME_ADITIONS']\n",
    "    \n",
    "    parameter_dicts[ind]['TRAIN_MODELNAME'] = 'experiment_' + this_run['GAME_MODE'] + '_gamma' + str(this_run['GAMMA']) + \\\n",
    "                '_epsdecay' + str(this_run['EPS_DECAY']) + '_targetupdate' + str(this_run['TARGET_UPDATE']) + \\\n",
    "                '_waittime' + str(this_run['WAITTIME']) + '_kernel' + str(this_run['KERNEL']) + '_stride' + \\\n",
    "                str(this_run['STRIDE']) + '_lr'+str(TRAIN_LR) + '_freeze'+ \\\n",
    "                str(this_run['CONV_FREEZE_LAYER'])+'_freezetime' + str(this_run['FREEZE_LAYER_TIME']) + '_loss' + \\\n",
    "                str(this_run['LOSS_TYPE']) + str(this_run['EWC_IMPORTANCE']) + this_run['TRAIN_MODELNAME_ADITIONS']\n",
    "    \n",
    "    \n",
    "    \n",
    "    with open('../params/'+experiment_name + '_' + str(ind) + '.params', 'w') as f:\n",
    "        json.dump(parameter_dicts[ind], f)\n",
    "\n",
    "print('num_runs:', len(parameter_dicts))        \n",
    "        \n",
    "# archive code\n",
    "if not os.path.exists('/fs/clip-realspeech/projects/vid_game/software/archive/'+experiment_name):\n",
    "    os.makedirs('/fs/clip-realspeech/projects/vid_game/software/archive/'+experiment_name) \n",
    "shutil.copytree('/fs/clip-realspeech/projects/vid_game/software/VidGameRL', '/fs/clip-realspeech/projects/vid_game/software/archive/'+experiment_name+'1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch jobs here \n",
    "for run in parameter_dicts:\n",
    "    os.system(' '.join(['sbatch run_acousticgame.sh', experiment_name, EXPERIMENT, run['param_name'], run['model_id'], str(gpu), str(stage), str(num_runs)]))\n",
    "# EDITED: RUN_BATCH.SH GAME INSTEAD OF RUN_ACOUSTICGAME.SH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audneurorl] *",
   "language": "python",
   "name": "conda-env-audneurorl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
